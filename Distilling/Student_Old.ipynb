{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f280853fc50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "# %matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "import utils\n",
    "from utils.dataset import SegmentationDataSet\n",
    "from utils.printer import source_printer\n",
    "from utils.printer import target_printer\n",
    "import utils.model as model\n",
    "from utils.model import UNet\n",
    "from utils.model import YNet\n",
    "from utils.model import Recons_net\n",
    "from utils.model import ClassifNet\n",
    "from utils.utils import getLossAccuracyOnDataset\n",
    "from utils.utils import preprocessing\n",
    "from utils.utils import IoU\n",
    "from utils.utils import postprocessing\n",
    "from utils.utils import dice_coeff\n",
    "from utils.utils import multiclass_dice_coeff\n",
    "from utils.utils import dice_loss\n",
    "from utils.utils import smooth\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "# manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_show(img, cmap=\"gray\", title=\"\"):\n",
    "    # cv.namedWindow(title, cv.WINDOW_NORMAL)\n",
    "    # cv.imshow(title, img)\n",
    "    print(title)\n",
    "    plt.imshow(img, cmap)\n",
    "    # display that image\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    transform = transforms.ToPILImage()\n",
    "    return transform(tensor)\n",
    "\n",
    "\n",
    "def image_to_tensor(image):\n",
    "    transform_1 = transforms.ToPILImage()\n",
    "    transform_2 = transforms.ToTensor()\n",
    "    img_tensor = transform_2(transform_1(image))\n",
    "    return img_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = str(datetime.now()).split(' ')[0]\n",
    "heure = str(datetime.now()).split(' ')[1].split('.')[0]\n",
    "\n",
    "# Root directory for dataset\n",
    "# Refaire nos data folder et tout pour que ce soit\n",
    "# au format demandé par le dataloader\n",
    "\n",
    "training_set_name = \"MNIST_STUDENT\"+\"_\"+str(date)+\"_\"+str(heure)\n",
    "\n",
    "\n",
    "dataset_folder = \"xxx\"\n",
    "train_list = dataset_folder+\"patches/xxx.txt\"\n",
    "test_list = dataset_folder+\"patches/xxx.txt\"\n",
    "\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 10\n",
    "\n",
    "# Batch size during training (low batch_size if there are memory issues)\n",
    "batch_size = 10\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size_source = 256\n",
    "image_size_target = 256\n",
    "image_size_discriminator = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Learning rate for optimizers\n",
    "learning_rate = 1e-5  # e-5\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "# Saves every batch_save_interval\n",
    "batch_save_interval = 2\n",
    "\n",
    "# some net variable\n",
    "amp = False\n",
    "\n",
    "\n",
    "saving_folder = \"../Data/Saves/\" + training_set_name\n",
    "\n",
    "# We create this folder (only if it doesn't exists) to save weights of the training at some keys epoch\n",
    "if not os.path.exists(saving_folder):\n",
    "    os.mkdir(saving_folder)\n",
    "    os.mkdir(saving_folder+\"/loss-dice_listes\")\n",
    "    os.mkdir(saving_folder+\"/newtork_weigths\")\n",
    "    os.mkdir(saving_folder+\"/training_monitoring\")\n",
    "\n",
    "log_file = open(saving_folder+\"/log+\"+\"_\"+date+\"_\"+heure+\".txt\", \"w\")\n",
    "\n",
    "log_file.write(\"dataset_folder :\"+dataset_folder+\"\\n\")\n",
    "log_file.write(\"batch_size=\"+str(batch_size)+\"\\n\")\n",
    "log_file.write(\"learning_rate_net=\"+str(learning_rate)+\"\\n\")\n",
    "log_file.write(\"num_epoch=\"+str(num_epochs)+\"\\n\")\n",
    "log_file.write(\"nc=\"+str(nc)+\"\\n\")\n",
    "log_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of gpus : 1\n",
      "device ID cuda:0\n",
      "nom du GPU NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "print(\"number of gpus :\", torch.cuda.device_count())\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (\n",
    "    torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# On regarde l'identifiant du GPU ou CPU sur lequel on travaille\n",
    "print(\"device ID\", device)\n",
    "print(\"nom du GPU\", torch.cuda.get_device_name(device))  # On vérifie son \"nom\"\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries 60000\n",
      "Number of training entries 42000\n",
      "Number of testing entries 9000\n",
      "Number of validation entries 9000\n",
      "SUM = 60000\n",
      "0 8\n",
      "1 9\n",
      "2 1\n",
      "3 8\n",
      "4 7\n",
      "5 8\n",
      "6 1\n",
      "7 7\n",
      "8 9\n",
      "9 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/miniconda3/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after filtering:\n",
      "37611\n",
      "33767\n",
      "29577\n",
      "25437\n",
      "Sample of classes contained in filtered 7 :\n",
      "tensor([4, 1, 1, 0, 5, 8, 3, 3, 0, 3])\n",
      "Sample of classes contained in filtered 7 5 9 2: \n",
      "tensor([0, 0, 4, 1, 3, 1, 4, 4, 2, 1])\n",
      "images source :  torch.Size([10, 1, 28, 28])\n",
      "mask source : torch.Size([10])\n",
      "tensor([5, 1, 1, 9, 3, 6, 1, 1, 9, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f26e0488be0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For data augmentation\n",
    "\n",
    "geometric_augs = [\n",
    "    # transforms.Resize((256, 256)), # Makes it easier to process using net\n",
    "    # transforms.RandomRotation(degrees=(0, 180)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    # transforms.RandomRotation(45),\n",
    "]\n",
    "\n",
    "color_augs = [\n",
    "    # transforms.ColorJitter(hue=0.05, saturation=0.4)\n",
    "]\n",
    "\n",
    "\n",
    "def make_tfs(augs):\n",
    "    return transforms.Compose([transforms.ToPILImage()]+augs + [transforms.ToTensor()])\n",
    "\n",
    "\n",
    "tfs = transforms.Compose(geometric_augs)\n",
    "\n",
    "\"\"\"\n",
    "# Importation des images et masques de i3\n",
    "dataset = SegmentationDataSet(root=dataset_folder,\n",
    "                              list_path=train_list,\n",
    "                              transform_img=make_tfs(\n",
    "                                  geometric_augs + color_augs),\n",
    "                              transform_label=make_tfs(geometric_augs)\n",
    "                              )\n",
    "\"\"\"\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "data = dset.MNIST(\"/var/tmp/\", train=True, download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize(\n",
    "                          (0.1307,), (0.3081,))\n",
    "                  ]))\n",
    "\n",
    "n_entries = len(data)\n",
    "train_split = 70/100\n",
    "validation_split = 50/100\n",
    "\n",
    "n_train = int(train_split*n_entries)\n",
    "n_test = int(((1-train_split)*(1-validation_split))*n_entries)\n",
    "n_validation = int(((1-train_split)*(validation_split))*n_entries)\n",
    "\n",
    "if (n_train + n_test + n_validation) != n_entries:\n",
    "    # Add one to the validation set\n",
    "    n_validation+=1\n",
    "\n",
    "print(\"Number of entries\", n_entries)\n",
    "print(\"Number of training entries\", n_train)\n",
    "print(\"Number of testing entries\", n_test)\n",
    "print(\"Number of validation entries\", n_validation)\n",
    "print(\"SUM =\", n_train+n_test+n_validation)\n",
    "\n",
    "train_data, test_data, validation_data = random_split(\n",
    "    data, [n_train, n_test, n_validation])\n",
    "\n",
    "\n",
    "filtered_7_indices = []\n",
    "filtered_7_5_indices = []\n",
    "filtered_7_5_9_indices = []\n",
    "filtered_7_5_9_2_indices = []\n",
    "for i in range(len(train_data)):\n",
    "    data_class = train_data[i][1]\n",
    "    if data_class != 7:\n",
    "        filtered_7_indices.append(i)\n",
    "        if data_class != 5:\n",
    "            filtered_7_5_indices.append(i)\n",
    "            if data_class != 9:\n",
    "                filtered_7_5_9_indices.append(i)\n",
    "                if data_class != 2:\n",
    "                    filtered_7_5_9_2_indices.append(i)\n",
    "\n",
    "    if i < 10:\n",
    "        print(i, train_data[i][1])\n",
    "\n",
    "\n",
    "filtered_7_train_data = torch.utils.data.Subset(train_data, filtered_7_indices)\n",
    "filtered_7_5_train_data = torch.utils.data.Subset(train_data, filtered_7_5_indices)\n",
    "filtered_7_5_9_train_data = torch.utils.data.Subset(train_data, filtered_7_5_9_indices)\n",
    "filtered_7_5_9_2_train_data = torch.utils.data.Subset(\n",
    "    train_data, filtered_7_5_9_2_indices)\n",
    "\n",
    "\n",
    "print(\"Size after filtering:\")\n",
    "print(len(filtered_7_train_data))\n",
    "print(len(filtered_7_5_train_data))\n",
    "print(len(filtered_7_5_9_train_data))\n",
    "print(len(filtered_7_5_9_2_train_data))\n",
    "\n",
    "\n",
    "# Dataloader\n",
    "filtered_7_train_dataloader = torch.utils.data.DataLoader(filtered_7_train_data,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=workers)\n",
    "\n",
    "filtered_7_5_train_dataloader = torch.utils.data.DataLoader(filtered_7_5_train_data,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        num_workers=workers)\n",
    "\n",
    "filtered_7_5_9_train_dataloader = torch.utils.data.DataLoader(filtered_7_5_9_train_data,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        num_workers=workers)\n",
    "\n",
    "filtered_7_5_9_2_train_dataloader = torch.utils.data.DataLoader(filtered_7_5_9_train_data,\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              shuffle=True,\n",
    "                                                              num_workers=workers)\n",
    "\n",
    "\n",
    "print(\"Sample of classes contained in filtered 7 :\")\n",
    "print(next(iter(filtered_7_train_dataloader))[1])\n",
    "print(\"Sample of classes contained in filtered 7 5 9 2: \")\n",
    "print(next(iter(filtered_7_5_9_2_train_dataloader))[1])\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=workers)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=workers)\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_data,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=workers)\n",
    "\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "# On affiche quelques exemple du batch pour vérifier qu'on a bien importé les données\n",
    "print(\"images source : \", batch[0].shape)\n",
    "print(\"mask source :\", batch[1].shape)\n",
    "\n",
    "\n",
    "print(batch[1])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training images source - a batch\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(batch[0].to(\n",
    "    device)[:64], padding=2, normalize=True).cpu(), (1, 2, 0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural net architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load or create neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are running U-Net on : NVIDIA GeForce GTX 1080 Ti\n",
      "Teacher network summary\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 1200]                942,000\n",
      "├─Linear: 1-2                            [-1, 1200]                1,441,200\n",
      "├─Linear: 1-3                            [-1, 10]                  12,010\n",
      "==========================================================================================\n",
      "Total params: 2,395,210\n",
      "Trainable params: 2,395,210\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 2.39\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 9.14\n",
      "Estimated Total Size (MB): 9.16\n",
      "==========================================================================================\n",
      "Student network summary\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 30]                  23,550\n",
      "├─Linear: 1-2                            [-1, 10]                  310\n",
      "==========================================================================================\n",
      "Total params: 23,860\n",
      "Trainable params: 23,860\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.02\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.09\n",
      "Estimated Total Size (MB): 0.09\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Linear: 1-1                            [-1, 30]                  23,550\n",
       "├─Linear: 1-2                            [-1, 10]                  310\n",
       "==========================================================================================\n",
       "Total params: 23,860\n",
       "Trainable params: 23,860\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.02\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.09\n",
       "Estimated Total Size (MB): 0.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_student_model():\n",
    "    # STUDENT\n",
    "    student_model = model.StudentNetworkSmall(1, 10)\n",
    "    # Load NN\n",
    "    if False:\n",
    "        state_dict = torch.load(\n",
    "            \"\")\n",
    "        student_model.load_state_dict(state_dict)\n",
    "    student_model.to(device=device)\n",
    "\n",
    "    if (device.type == 'cuda') and (ngpu > 1):\n",
    "        print(\"Data Parallel\")\n",
    "        student_model = nn.DataParallel(student_model, list(range(ngpu)))\n",
    "    \n",
    "    return student_model\n",
    "\n",
    "\n",
    "def load_teacher_model():\n",
    "    # TEACHER\n",
    "    teacher_model = model.TeacherNetwork(1, 10)\n",
    "    # Load NN\n",
    "    if True:\n",
    "        state_dict = torch.load(\n",
    "            \"../Data/Saves/MNIST_TEACHER/newtork_weigths/net_epoch8_acc0.997_loss0.011.pth\")\n",
    "        teacher_model.load_state_dict(state_dict)\n",
    "    teacher_model.to(device=device)\n",
    "\n",
    "    if (device.type == 'cuda') and (ngpu > 1):\n",
    "        print(\"Data Parallel\")\n",
    "        teacher_model = nn.DataParallel(teacher_model, list(range(ngpu)))\n",
    "\n",
    "    return teacher_model\n",
    "\n",
    "\n",
    "# Other\n",
    "\n",
    "\n",
    "# On revérifie qu'on tourne bien le réseau de neuronnes sur le GPU\n",
    "print(\"We are running U-Net on :\", torch.cuda.get_device_name(device))\n",
    "\n",
    "print(\"Teacher network summary\")\n",
    "summary(load_teacher_model(), (1, 28, 28))\n",
    "\n",
    "print(\"Student network summary\")\n",
    "summary(load_student_model(), (1, 28, 28))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainStep(model, data, optimizer):\n",
    "\t\"\"\"\n",
    "\tOne training step of the network: forward prop + backprop + update parameters\n",
    "\tReturn: (loss, accuracy) of current batch\n",
    "\t\"\"\"\n",
    "\tX, y = data\n",
    "\n",
    "\tX = X.to(\n",
    "            device=device, dtype=torch.float32)\n",
    "\ty = y.to(\n",
    "\t\tdevice=device, dtype=torch.long)\n",
    "\t\n",
    "\toptimizer.zero_grad()\n",
    "\tpred = model(X)\n",
    "\tloss = F.cross_entropy(pred, y)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\taccuracy = float(torch.sum(torch.argmax(\n",
    "\t\tpred, dim=1) == y).item()) / y.shape[0]\n",
    "\treturn loss, accuracy\n",
    "\n",
    "\n",
    "def validateStep(model, data):\n",
    "\tX, y = data\n",
    "\n",
    "\tX = X.to(\n",
    "            device=device, dtype=torch.float32)\n",
    "\ty = y.to(\n",
    "\t\tdevice=device, dtype=torch.long)\n",
    "\n",
    "\tpred = model(X)\n",
    "\tloss = F.cross_entropy(pred, y).item()\n",
    "\taccuracy = float(torch.sum(torch.argmax(\n",
    "\t\tpred, dim=1) == y).item()) / y.shape[0]\n",
    "\treturn loss, accuracy\n",
    "\n",
    "\n",
    "teacher_model = load_teacher_model()\n",
    "\n",
    "\n",
    "def studentTrainStepDistillationMNIST(model, data, optimizer):\n",
    "\t\"\"\"\n",
    "\tOne training step of student network: forward prop + backprop + update parameters\n",
    "\tReturn: (loss, accuracy) of current batch\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tX, y = data\n",
    "\n",
    "\tX = X.to(\n",
    "            device=device, dtype=torch.float32)\n",
    "\ty = y.to(\n",
    "\t\tdevice=device, dtype=torch.long)\n",
    "\t\n",
    "\tT = 1.0  # temperature for distillation loss\n",
    "\t# Using a higher value for T produces a softer probability distribution over classes\n",
    "\talpha = 1.0\n",
    "\t# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "\t# loss = alpha * st + (1 - alpha) * tt\n",
    "\toptimizer.zero_grad()\n",
    "\tteacher_pred = None\n",
    "\tif (alpha > 0):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tteacher_model.eval()\n",
    "\t\t\tteacher_pred = teacher_model(X)\n",
    "\tstudent_pred = model(X)\n",
    "\tloss = studentLoss(teacher_pred, student_pred, y, T, alpha)\n",
    "\tloss.backward() # Generates error : element 0 of tensors does not require grad and does not have a grad_fn\n",
    "\toptimizer.step()\n",
    "\taccuracy = float(torch.sum(torch.argmax(\n",
    "\t\tstudent_pred, dim=1) == y).item()) / y.shape[0]\n",
    "\treturn loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "def studentTrainStep(teacher_net, student_net, studentLossFunction, optimizer, X, y, T, alpha):\n",
    "\t\"\"\"\n",
    "\tOne training step of student network: forward prop + backprop + update parameters\n",
    "\tReturn: (loss, accuracy) of current batch\n",
    "\t\"\"\"\n",
    "\toptimizer.zero_grad()\n",
    "\tteacher_pred = None\n",
    "\tif (alpha > 0):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tteacher_pred = teacher_net(X)\n",
    "\tstudent_pred = student_net(X)\n",
    "\tloss = studentLossFunction(teacher_pred, student_pred, y, T, alpha)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\taccuracy = float(torch.sum(torch.argmax(\n",
    "\t\tstudent_pred, dim=1) == y).item()) / y.shape[0]\n",
    "\treturn loss, accuracy\n",
    "\n",
    "def studentLoss(teacher_pred, student_pred, y, T, alpha):\n",
    "\t\"\"\"\n",
    "\t\tLoss function for student network: Loss = alpha * (distillation loss with soft-target) + (1 - alpha) * (cross-entropy loss with true label)\n",
    "\t\tReturn: loss\n",
    "\t\t\"\"\"\n",
    "\tif (alpha > 0):\n",
    "\t\tloss = F.kl_div(F.log_softmax(student_pred / T, dim=1), F.softmax(teacher_pred / T, dim=1),\n",
    "\t\t\t\t\t\treduction='batchmean') * (T ** 2) * alpha + F.cross_entropy(student_pred, y) * (1 - alpha)\n",
    "\telse:\n",
    "\t\tloss = F.cross_entropy(student_pred, y)\n",
    "\treturn loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function \n",
    "def train(model, train_loader, validate_loader, trainStepFun, validateStepFun):\n",
    "    \n",
    "    scheduler_params = dict(max_lr=1e-3,\n",
    "                            epochs=num_epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "    optimizer = optim.AdamW(list(model.parameters()))\n",
    "    scheduler_global = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, **scheduler_params)  # goal: maximize Dice score\n",
    "    grad_scaler_global = torch.cuda.amp.GradScaler(\n",
    "        enabled=amp)  # Default parameter\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    interval = []\n",
    "    interval_count = 0\n",
    "    validation_accuracy_progression = []\n",
    "    validation_loss_progression = []\n",
    "    print(\"Begin training...\") \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        running_train_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        running_vall_loss = 0.0\n",
    "        total = 0\n",
    "\n",
    "        # Training Loop\n",
    "        for data in train_loader: \n",
    "        #for data in enumerate(train_loader, 0): \n",
    "            model.train()\n",
    "            loss, acc = trainStepFun(model, data, optimizer)\n",
    "            running_train_loss += loss #  # track the loss value\n",
    " \n",
    "        # Calculate training loss value \n",
    "        train_loss_value = running_train_loss/len(train_loader) \n",
    "        \n",
    "        \n",
    "        # Validation Loop \n",
    "        with torch.no_grad(): # Why not ?\n",
    "            for data in validate_loader:\n",
    "                model.eval()\n",
    "                ## loss, acc = trainStepFun(model, data)\n",
    "                loss, acc = validateStepFun(model, data)\n",
    "\n",
    "                # The label with the highest value will be our prediction \n",
    "                running_vall_loss += loss\n",
    "                total += 1\n",
    "                running_accuracy += acc\n",
    "                                            \n",
    "                validation_accuracy_progression.append(acc)\n",
    "                validation_loss_progression.append(loss)\n",
    "                interval_count += 1\n",
    "                interval.append(interval_count)\n",
    "    \n",
    "        # Calculate validation loss value \n",
    "        val_loss_value = running_vall_loss/len(validate_loader) \n",
    "                \n",
    "        # Calculate accuracy as the number of correct predictions in the validation batch divided by the total number of predictions done.  \n",
    "        accuracy = (100.0 * running_accuracy / total)     \n",
    " \n",
    "        # Save the model if the accuracy is the best \n",
    "        if accuracy > best_accuracy:\n",
    "            torch.save(model.state_dict(), saving_folder +\n",
    "                       \"/newtork_weigths/model_epoch{:}_validation_accuracy{:.3f}_train_loss{:.3f}.pth\".format(epoch, accuracy, train_loss_value))\n",
    "            best_accuracy = accuracy\n",
    "         \n",
    "        # Print the statistics of the epoch \n",
    "        print('Completed training batch', epoch, 'Training Loss is: %.4f' %train_loss_value,\n",
    "               'Validation Loss is: %.4f' %val_loss_value, 'Accuracy is %d %%' % (accuracy))\n",
    "        \n",
    "        validation_accuracy_smooth = smooth(validation_accuracy_progression, 0.99)\n",
    "        validation_loss_smooth = smooth(validation_loss_progression, 0.99)\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.clf()\n",
    "        plt.plot(interval, validation_accuracy_smooth,\n",
    "                 'g-', label='Global accuracy')\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Accuracy Value\")\n",
    "        plt.title(\"Accuracy Monitoring among validation\")\n",
    "        plt.legend()\n",
    "        plt.savefig(saving_folder+\"/training_monitoring/accuracy_\" +\n",
    "                    str(epoch)+\"_epoch.png\")\n",
    "        \n",
    "        if (epoch == num_epochs):\n",
    "            plt.show()\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.clf()\n",
    "        plt.plot(interval, validation_loss_smooth,\n",
    "                 'r-', label='Global loss')\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Loss Value\")\n",
    "        plt.title(\"Loss Monitoring among validation\")\n",
    "        plt.legend()\n",
    "        plt.savefig(saving_folder+\"/training_monitoring/loss_\" +\n",
    "                    str(epoch)+\"_epoch.png\")\n",
    "        \n",
    "        if (epoch == num_epochs):\n",
    "            plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the model\n",
    "def test(model, test_loader):\n",
    "    running_accuracy = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, outputs = data\n",
    "            outputs = outputs.to(torch.float32)\n",
    "            predicted_outputs = model(inputs)\n",
    "            _, predicted = torch.max(predicted_outputs, 1)\n",
    "            total += outputs.size(0)\n",
    "            running_accuracy += (predicted == outputs).sum().item()\n",
    "\n",
    "        print('Accuracy of the model based on the test set',\n",
    "              'inputs is: %d %%' % (100 * running_accuracy / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With trainStep\n",
      "Normal\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for ** or pow(): 'AdamW' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m#print(\"Teacher\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m#train(load_teacher_model(), train_dataloader, validation_dataloader,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#      trainStep, validateStep)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNormal\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m train(load_student_model(), train_dataloader, validation_dataloader,\n\u001b[1;32m      9\u001b[0m       trainStep, validateStep)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m7 Filtering\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m train(load_student_model(), filtered_7_train_dataloader, validation_dataloader,\n\u001b[1;32m     13\u001b[0m       trainStep, validateStep)\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, validate_loader, trainStepFun, validateStepFun)\u001b[0m\n\u001b[1;32m      4\u001b[0m scheduler_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(max_lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m,\n\u001b[1;32m      5\u001b[0m                         epochs\u001b[39m=\u001b[39mnum_epochs, steps_per_epoch\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_loader))\n\u001b[1;32m      7\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdamW(\u001b[39mlist\u001b[39m(model\u001b[39m.\u001b[39mparameters()))\n\u001b[1;32m      8\u001b[0m scheduler_global \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mOneCycleLR(\n\u001b[0;32m----> 9\u001b[0m     optimizer \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mscheduler_params)  \u001b[39m# goal: maximize Dice score\u001b[39;00m\n\u001b[1;32m     10\u001b[0m grad_scaler_global \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mGradScaler(\n\u001b[1;32m     11\u001b[0m     enabled\u001b[39m=\u001b[39mamp)  \u001b[39m# Default parameter\u001b[39;00m\n\u001b[1;32m     13\u001b[0m best_accuracy \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for ** or pow(): 'AdamW' and 'dict'"
     ]
    }
   ],
   "source": [
    "print(\"With trainStep\")\n",
    "\n",
    "#print(\"Teacher\")\n",
    "#train(load_teacher_model(), train_dataloader, validation_dataloader,\n",
    "#      trainStep, validateStep)\n",
    "\n",
    "print(\"Normal\")\n",
    "train(load_student_model(), train_dataloader, validation_dataloader,\n",
    "      trainStep, validateStep)\n",
    "\n",
    "print(\"7 Filtering\")\n",
    "train(load_student_model(), filtered_7_train_dataloader, validation_dataloader,\n",
    "      trainStep, validateStep)\n",
    "\n",
    "print(\"7 5 Filtering\")\n",
    "train(load_student_model(), filtered_7_5_train_dataloader, validation_dataloader,\n",
    "      trainStep, validateStep)\n",
    "\n",
    "print(\"7 5 9 Filtering\")\n",
    "train(load_student_model(), filtered_7_5_9_train_dataloader, validation_dataloader,\n",
    "      trainStep, validateStep)\n",
    "\n",
    "print(\"7 5 9 2 Filtering\")\n",
    "train(load_student_model(), filtered_7_5_9_2_train_dataloader, validation_dataloader,\n",
    "      trainStep, validateStep)\n",
    "\n",
    "\n",
    "print(\"With studentTrainStepDistillationMNIST\")\n",
    "\n",
    "print(\"Normal\")\n",
    "train(load_student_model(), train_dataloader, validation_dataloader,\n",
    "      studentTrainStepDistillationMNIST, validateStep)\n",
    "\n",
    "print(\"7 Filtering\")\n",
    "train(load_student_model(), filtered_7_train_dataloader, validation_dataloader,\n",
    "      studentTrainStepDistillationMNIST, validateStep)\n",
    "\n",
    "print(\"7 5 Filtering\")\n",
    "train(load_student_model(), filtered_7_5_train_dataloader, validation_dataloader,\n",
    "      studentTrainStepDistillationMNIST, validateStep)\n",
    "\n",
    "print(\"7 5 9 Filtering\")\n",
    "train(load_student_model(), filtered_7_5_9_train_dataloader, validation_dataloader,\n",
    "      studentTrainStepDistillationMNIST, validateStep)\n",
    "\n",
    "print(\"7 5 9 2 Filtering\")\n",
    "train(load_student_model(), filtered_7_5_9_2_train_dataloader, validation_dataloader,\n",
    "      studentTrainStepDistillationMNIST, validateStep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"global_step =  0\n",
    "n_train = len(filtered_train_data)\n",
    "print(n_train)\n",
    "\n",
    "T = 1.0 # temperature for distillation loss\n",
    "# Using a higher value for T produces a softer probability distribution over classes\n",
    "alpha = 1.0\n",
    "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "# loss = alpha * st + (1 - alpha) * tt\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "\n",
    "source_dice = []\n",
    "intervalle = []\n",
    "\n",
    "L_seg_list = []\n",
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "L_s_list = []\n",
    "\n",
    "compteur_plot = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    cpt_it = 0\n",
    "    with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='img') as pbar:\n",
    "\n",
    "        for i, data in enumerate(filtered_train_dataloader, 0):\n",
    "            student_model.train()\n",
    "            teacher_model.eval()\n",
    "\n",
    "            cpt_it += 1\n",
    "\n",
    "            X, y = data\n",
    "\n",
    "            X = X.to(\n",
    "                device=device, dtype=torch.float32)\n",
    "            y = y.to(\n",
    "                device=device, dtype=torch.long)\n",
    "\n",
    "            # Pass Data Trought net before optimizing everything\n",
    "\n",
    "            loss, acc = studentTrainStep(teacher_model, student_model, studentLoss, optimizer_global, X, y, T, alpha)\n",
    "            \n",
    "\n",
    "            L_global = loss\n",
    "\n",
    "            ###########################################################\n",
    "            # Evaluation on the Training Set\n",
    "            ###########################################################\n",
    "\n",
    "            student_model.eval()\n",
    "\n",
    "            intervalle.append(compteur_plot)\n",
    "            compteur_plot += 1\n",
    "\n",
    "            global_step += 1\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "\n",
    "            pbar.update(X.shape[0])\n",
    "            pbar.set_postfix(\n",
    "                **{'loss (batch)': epoch_loss/cpt_it, \"accuracy (batch)\": epoch_acc/cpt_it})\n",
    "            # pbar.set_postfix(**{'dice target': dice_target})\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "            acc_list.append(acc)\n",
    "# print(\"whole epoch target dice mean :\", sum(dice_score_target)/cpt_it)\n",
    "        if (epoch % batch_save_interval == 0):  # and epoch != 0 :\n",
    "\n",
    "            loss_smooth = smooth(loss_list, 0.99)\n",
    "            acc_smooth = smooth(acc_list, 0.99)\n",
    "\n",
    "            torch.save(student_model.state_dict(), saving_folder +\n",
    "                       \"/newtork_weigths/net_epoch{:}_acc{:.3f}_loss{:.3f}.pth\".format(epoch, epoch_acc/cpt_it, epoch_loss/cpt_it))\n",
    "\n",
    "            plt.figure(1)\n",
    "            plt.clf()\n",
    "            plt.plot(intervalle, acc_smooth, 'r-', label='Global accuracy')\n",
    "            plt.xlabel(\"iterations\")\n",
    "            plt.ylabel(\"Accuracy Value\")\n",
    "            plt.title(\"Accuracy Monitoring among training\")\n",
    "            plt.legend()\n",
    "            plt.savefig(saving_folder+\"/training_monitoring/acc_\" +\n",
    "                        str(epoch)+\"_epoch.png\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(1)\n",
    "            plt.clf()\n",
    "            plt.plot(intervalle, loss_smooth, 'r-', label='Global loss')\n",
    "            plt.xlabel(\"iterations\")\n",
    "            plt.ylabel(\"Loss Value\")\n",
    "            plt.title(\"Loss Monitoring among training\")\n",
    "            plt.legend()\n",
    "            plt.savefig(saving_folder+\"/training_monitoring/loss_\" +\n",
    "                        str(epoch)+\"_epoch.png\")\n",
    "            plt.show()\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64ccc0bcb017b315b1a5d283b11f23a53f931f6e7f818fe9c7c964553a277152"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
