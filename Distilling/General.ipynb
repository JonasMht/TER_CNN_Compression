{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8a95b22fc0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "# %matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "import utils\n",
    "from utils.dataset import SegmentationDataSet\n",
    "from utils.printer import source_printer\n",
    "from utils.printer import target_printer\n",
    "from utils.model import GenericNetwork\n",
    "from utils.model import TeacherNetwork\n",
    "from utils.model import StudentNetworkSmall\n",
    "from utils.model import UNet\n",
    "from utils.model import YNet\n",
    "from utils.model import Recons_net\n",
    "from utils.model import ClassifNet\n",
    "from utils.utils import getLossAccuracyOnDataset\n",
    "from utils.utils import preprocessing\n",
    "from utils.utils import IoU\n",
    "from utils.utils import postprocessing\n",
    "from utils.utils import dice_coeff\n",
    "from utils.utils import multiclass_dice_coeff\n",
    "from utils.utils import dice_loss\n",
    "from utils.utils import smooth\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "# manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_show(img, cmap=\"gray\", title=\"\"):\n",
    "    # cv.namedWindow(title, cv.WINDOW_NORMAL)\n",
    "    # cv.imshow(title, img)\n",
    "    print(title)\n",
    "    plt.imshow(img, cmap)\n",
    "    # display that image\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    transform = transforms.ToPILImage()\n",
    "    return transform(tensor)\n",
    "\n",
    "\n",
    "def image_to_tensor(image):\n",
    "    transform_1 = transforms.ToPILImage()\n",
    "    transform_2 = transforms.ToTensor()\n",
    "    img_tensor = transform_2(transform_1(image))\n",
    "    return img_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, path=\"\"):\n",
    "    if len(path)>0:\n",
    "        state_dict = torch.load(path)\n",
    "        model.load_state_dict(state_dict)\n",
    "    model.to(device=device)\n",
    "\n",
    "    if (device.type == 'cuda') and (ngpu > 1):\n",
    "        print(\"Data Parallel\")\n",
    "        model = nn.DataParallel(model, list(range(ngpu)))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def load_student_model():\n",
    "    # STUDENT\n",
    "    return load_model(StudentNetworkSmall())\n",
    "\n",
    "\n",
    "def load_teacher_model():\n",
    "    # TEACHER\n",
    "    return load_model(TeacherNetwork())\n",
    "\n",
    "# Other\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Function that returns a list of paths in a folder that start with a word\n",
    "def get_path_list(path, start_with=\"\"):\n",
    "    path_list = [osp.join(path, f) for f in os.listdir(path) if f.startswith(start_with)]\n",
    "    return path_list\n",
    "\n",
    "# Function that returns the names in a path list with the last number in the name\n",
    "def get_last_number_in_name(path_list):\n",
    "    last_number = [int(f.split(\"_\")[-1].split(\".\")[0]) for f in path_list]\n",
    "    return last_number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = str(datetime.now()).split(' ')[0]\n",
    "heure = str(datetime.now()).split(' ')[1].split('.')[0]\n",
    "\n",
    "# Root directory for dataset\n",
    "# Refaire nos data folder et tout pour que ce soit\n",
    "# au format demandé par le dataloader\n",
    "\n",
    "training_set_name = \"MNIST_Distillation\"+\"_\"+str(date)+\"_\"+str(heure)\n",
    "\n",
    "alternative_name = True\n",
    "if alternative_name:\n",
    "    training_set_name = \"MNIST_Distillation_2023-03-03_19:09:12\"\n",
    "\n",
    "dataset_folder = \"xxx\"\n",
    "train_list = dataset_folder+\"patches/xxx.txt\"\n",
    "test_list = dataset_folder+\"patches/xxx.txt\"\n",
    "\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 10\n",
    "\n",
    "# Batch size during training (low batch_size if there are memory issues)\n",
    "batch_size = 10\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size_source = 256\n",
    "image_size_target = 256\n",
    "image_size_discriminator = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Learning rate for optimizers\n",
    "learning_rate = 1e-5  # e-5\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "# Saves every batch_save_interval\n",
    "batch_save_interval = 2\n",
    "\n",
    "# some net variable\n",
    "amp = False\n",
    "\n",
    "save_folder =  \"../Data/Saves/\" + training_set_name\n",
    "\n",
    "if not os.path.exists(\"../Data\"):\n",
    "    os.mkdir(\"../Data\")\n",
    "if not os.path.exists(\"../Data/Saves\" ):\n",
    "    os.mkdir(\"../Data/Saves\" )\n",
    "\n",
    "# We create this folder (only if it doesn't exists) to save weights of the training at some keys epoch\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)\n",
    "    os.mkdir(save_folder+\"/loss-dice_listes\")\n",
    "    os.mkdir(save_folder+\"/newtork_weigths\")\n",
    "    os.mkdir(save_folder+\"/training_monitoring\")\n",
    "\n",
    "log_file = open(save_folder+\"/log+\"+\"_\"+date+\"_\"+heure+\".txt\", \"w\")\n",
    "\n",
    "log_file.write(\"dataset_folder :\"+dataset_folder+\"\\n\")\n",
    "log_file.write(\"batch_size=\"+str(batch_size)+\"\\n\")\n",
    "log_file.write(\"learning_rate_net=\"+str(learning_rate)+\"\\n\")\n",
    "log_file.write(\"num_epoch=\"+str(num_epochs)+\"\\n\")\n",
    "log_file.write(\"nc=\"+str(nc)+\"\\n\")\n",
    "log_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of gpus : 4\n",
      "device ID cuda:0\n",
      "nom du GPU NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "print(\"number of gpus :\", torch.cuda.device_count())\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (\n",
    "    torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# On regarde l'identifiant du GPU ou CPU sur lequel on travaille\n",
    "print(\"device ID\", device)\n",
    "print(\"nom du GPU\", torch.cuda.get_device_name(device))  # On vérifie son \"nom\"\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries 60000\n",
      "Number of training entries 42000\n",
      "Number of testing entries 9000\n",
      "Number of validation entries 9000\n",
      "SUM = 60000\n",
      "0 8\n",
      "1 9\n",
      "2 1\n",
      "3 8\n",
      "4 7\n",
      "5 8\n",
      "6 1\n",
      "7 7\n",
      "8 9\n",
      "9 7\n",
      "Size after filtering:\n",
      "37611\n",
      "33767\n",
      "29577\n",
      "25437\n",
      "Sample of classes contained in filtered 7 :\n",
      "tensor([4, 1, 1, 0, 5, 8, 3, 3, 0, 3])\n",
      "Sample of classes contained in filtered 7 5 9 2: \n",
      "tensor([0, 0, 4, 1, 3, 1, 4, 4, 2, 1])\n",
      "images source :  torch.Size([10, 1, 28, 28])\n",
      "mask source : torch.Size([10])\n",
      "tensor([5, 1, 1, 9, 3, 6, 1, 1, 9, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f88704bf828>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For data augmentation\n",
    "\n",
    "geometric_augs = [\n",
    "    # transforms.Resize((256, 256)), # Makes it easier to process using net\n",
    "    # transforms.RandomRotation(degrees=(0, 180)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    # transforms.RandomRotation(45),\n",
    "]\n",
    "\n",
    "color_augs = [\n",
    "    # transforms.ColorJitter(hue=0.05, saturation=0.4)\n",
    "]\n",
    "\n",
    "\n",
    "def make_tfs(augs):\n",
    "    return transforms.Compose([transforms.ToPILImage()]+augs + [transforms.ToTensor()])\n",
    "\n",
    "\n",
    "tfs = transforms.Compose(geometric_augs)\n",
    "\n",
    "\"\"\"\n",
    "# Importation des images et masques de i3\n",
    "dataset = SegmentationDataSet(root=dataset_folder,\n",
    "                              list_path=train_list,\n",
    "                              transform_img=make_tfs(\n",
    "                                  geometric_augs + color_augs),\n",
    "                              transform_label=make_tfs(geometric_augs)\n",
    "                              )\n",
    "\"\"\"\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "data = dset.MNIST(\"/var/tmp/\", train=True, download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize(\n",
    "                          (0.1307,), (0.3081,))\n",
    "                  ]))\n",
    "\n",
    "n_entries = len(data)\n",
    "train_split = 70/100\n",
    "validation_split = 50/100\n",
    "\n",
    "n_train = int(train_split*n_entries)\n",
    "n_test = int(((1-train_split)*(1-validation_split))*n_entries)\n",
    "n_validation = int(((1-train_split)*(validation_split))*n_entries)\n",
    "\n",
    "if (n_train + n_test + n_validation) != n_entries:\n",
    "    # Add one to the validation set\n",
    "    n_validation+=1\n",
    "\n",
    "print(\"Number of entries\", n_entries)\n",
    "print(\"Number of training entries\", n_train)\n",
    "print(\"Number of testing entries\", n_test)\n",
    "print(\"Number of validation entries\", n_validation)\n",
    "print(\"SUM =\", n_train+n_test+n_validation)\n",
    "\n",
    "train_data, test_data, validation_data = random_split(\n",
    "    data, [n_train, n_test, n_validation])\n",
    "\n",
    "\n",
    "filtered_7_indices = []\n",
    "filtered_7_5_indices = []\n",
    "filtered_7_5_9_indices = []\n",
    "filtered_7_5_9_2_indices = []\n",
    "for i in range(len(train_data)):\n",
    "    data_class = train_data[i][1]\n",
    "    if data_class != 7:\n",
    "        filtered_7_indices.append(i)\n",
    "        if data_class != 5:\n",
    "            filtered_7_5_indices.append(i)\n",
    "            if data_class != 9:\n",
    "                filtered_7_5_9_indices.append(i)\n",
    "                if data_class != 2:\n",
    "                    filtered_7_5_9_2_indices.append(i)\n",
    "\n",
    "    if i < 10:\n",
    "        print(i, train_data[i][1])\n",
    "\n",
    "\n",
    "filtered_7_train_data = torch.utils.data.Subset(train_data, filtered_7_indices)\n",
    "filtered_7_5_train_data = torch.utils.data.Subset(train_data, filtered_7_5_indices)\n",
    "filtered_7_5_9_train_data = torch.utils.data.Subset(train_data, filtered_7_5_9_indices)\n",
    "filtered_7_5_9_2_train_data = torch.utils.data.Subset(\n",
    "    train_data, filtered_7_5_9_2_indices)\n",
    "\n",
    "\n",
    "print(\"Size after filtering:\")\n",
    "print(len(filtered_7_train_data))\n",
    "print(len(filtered_7_5_train_data))\n",
    "print(len(filtered_7_5_9_train_data))\n",
    "print(len(filtered_7_5_9_2_train_data))\n",
    "\n",
    "\n",
    "# Dataloader\n",
    "filtered_7_train_dataloader = torch.utils.data.DataLoader(filtered_7_train_data,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=workers)\n",
    "\n",
    "filtered_7_5_train_dataloader = torch.utils.data.DataLoader(filtered_7_5_train_data,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        num_workers=workers)\n",
    "\n",
    "filtered_7_5_9_train_dataloader = torch.utils.data.DataLoader(filtered_7_5_9_train_data,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        num_workers=workers)\n",
    "\n",
    "filtered_7_5_9_2_train_dataloader = torch.utils.data.DataLoader(filtered_7_5_9_train_data,\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              shuffle=True,\n",
    "                                                              num_workers=workers)\n",
    "\n",
    "\n",
    "print(\"Sample of classes contained in filtered 7 :\")\n",
    "print(next(iter(filtered_7_train_dataloader))[1])\n",
    "print(\"Sample of classes contained in filtered 7 5 9 2: \")\n",
    "print(next(iter(filtered_7_5_9_2_train_dataloader))[1])\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=workers)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=workers)\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_data,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=workers)\n",
    "\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "# On affiche quelques exemple du batch pour vérifier qu'on a bien importé les données\n",
    "print(\"images source : \", batch[0].shape)\n",
    "print(\"mask source :\", batch[1].shape)\n",
    "\n",
    "\n",
    "print(batch[1])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training images source - a batch\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(batch[0].to(\n",
    "    device)[:64], padding=2, normalize=True).cpu(), (1, 2, 0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural net architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load or create neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are running U-Net on : NVIDIA GeForce RTX 2080 Ti\n",
      "Teacher network summary\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 1200]         942,000\n",
      "            Linear-2                 [-1, 1200]       1,441,200\n",
      "            Linear-3                   [-1, 10]          12,010\n",
      "================================================================\n",
      "Total params: 2,395,210\n",
      "Trainable params: 2,395,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 9.14\n",
      "Estimated Total Size (MB): 9.16\n",
      "----------------------------------------------------------------\n",
      "Student network summary\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 30]          23,550\n",
      "            Linear-2                   [-1, 10]             310\n",
      "================================================================\n",
      "Total params: 23,860\n",
      "Trainable params: 23,860\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.09\n",
      "Estimated Total Size (MB): 0.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# On revérifie qu'on tourne bien le réseau de neuronnes sur le GPU\n",
    "print(\"We are running U-Net on :\", torch.cuda.get_device_name(device))\n",
    "\n",
    "print(\"Teacher network summary\")\n",
    "summary(load_teacher_model(), (1, 28, 28))\n",
    "\n",
    "print(\"Student network summary\")\n",
    "summary(load_student_model(), (1, 28, 28))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainStep(model, data, optimizer):\n",
    "\t\"\"\"\n",
    "\tOne training step of the network: forward prop + backprop + update parameters\n",
    "\tReturn: (loss, accuracy) of current batch\n",
    "\t\"\"\"\n",
    "\tX, y = data\n",
    "\n",
    "\tX = X.to(\n",
    "            device=device, dtype=torch.float32)\n",
    "\ty = y.to(\n",
    "\t\tdevice=device, dtype=torch.long)\n",
    "\t\n",
    "\toptimizer.zero_grad()\n",
    "\tpred = model(X)\n",
    "\tloss = F.cross_entropy(pred, y)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\taccuracy = float(torch.sum(torch.argmax(\n",
    "\t\tpred, dim=1) == y).item()) / y.shape[0]\n",
    "\treturn loss, accuracy\n",
    "\n",
    "\n",
    "def testStep(model, data):\n",
    "\tX, y = data\n",
    "\n",
    "\tX = X.to(\n",
    "            device=device, dtype=torch.float32)\n",
    "\ty = y.to(\n",
    "\t\tdevice=device, dtype=torch.long)\n",
    "\n",
    "\tpred = model(X)\n",
    "\tloss = F.cross_entropy(pred, y).item()\n",
    "\taccuracy = float(torch.sum(torch.argmax(\n",
    "\t\tpred, dim=1) == y).item()) / y.shape[0]\n",
    "\treturn loss, accuracy\n",
    "\n",
    "\n",
    "teacher_model = load_teacher_model()\n",
    "\n",
    "\n",
    "def studentTrainStepDistillationMNIST(model, data, optimizer):\n",
    "\t\"\"\"\n",
    "\tOne training step of student network: forward prop + backprop + update parameters\n",
    "\tReturn: (loss, accuracy) of current batch\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tX, y = data\n",
    "\n",
    "\tX = X.to(\n",
    "            device=device, dtype=torch.float32)\n",
    "\ty = y.to(\n",
    "\t\tdevice=device, dtype=torch.long)\n",
    "\t\n",
    "\tT = 0.85  # temperature for distillation loss\n",
    "\t# Using a higher value for T produces a softer probability distribution over classes\n",
    "\talpha = 1.0\n",
    "\t# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "\t# loss = alpha * st + (1 - alpha) * tt\n",
    "\toptimizer.zero_grad()\n",
    "\tteacher_pred = None\n",
    "\tif (alpha > 0):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tteacher_model.eval()\n",
    "\t\t\tteacher_pred = teacher_model(X)\n",
    "\tstudent_pred = model(X)\n",
    "\tloss = studentLoss(teacher_pred, student_pred, y, T, alpha)\n",
    "\tloss.backward() # Generates error : element 0 of tensors does not require grad and does not have a grad_fn\n",
    "\toptimizer.step()\n",
    "\taccuracy = float(torch.sum(torch.argmax(\n",
    "\t\tstudent_pred, dim=1) == y).item()) / y.shape[0]\n",
    "\treturn loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "def studentTrainStep(teacher_net, student_net, studentLossFunction, optimizer, X, y, T, alpha):\n",
    "\t\"\"\"\n",
    "\tOne training step of student network: forward prop + backprop + update parameters\n",
    "\tReturn: (loss, accuracy) of current batch\n",
    "\t\"\"\"\n",
    "\toptimizer.zero_grad()\n",
    "\tteacher_pred = None\n",
    "\tif (alpha > 0):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tteacher_pred = teacher_net(X)\n",
    "\tstudent_pred = student_net(X)\n",
    "\tloss = studentLossFunction(teacher_pred, student_pred, y, T, alpha)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\taccuracy = float(torch.sum(torch.argmax(\n",
    "\t\tstudent_pred, dim=1) == y).item()) / y.shape[0]\n",
    "\treturn loss, accuracy\n",
    "\n",
    "def studentLoss(teacher_pred, student_pred, y, T, alpha):\n",
    "\t\"\"\"\n",
    "\t\tLoss function for student network: Loss = alpha * (distillation loss with soft-target) + (1 - alpha) * (cross-entropy loss with true label)\n",
    "\t\tReturn: loss\n",
    "\t\t\"\"\"\n",
    "\tif (alpha > 0):\n",
    "\t\tloss = F.kl_div(F.log_softmax(student_pred / T, dim=1), F.softmax(teacher_pred / T, dim=1),\n",
    "\t\t\t\t\t\treduction='batchmean') * (T ** 2) * alpha + F.cross_entropy(student_pred, y) * (1 - alpha)\n",
    "\telse:\n",
    "\t\tloss = F.cross_entropy(student_pred, y)\n",
    "\treturn loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function \n",
    "def train(model, train_loader, validate_loader, trainStepFun, testStepFun, epochs=20):\n",
    "    \n",
    "    scheduler_params = dict(max_lr=1e-3,\n",
    "                            epochs=epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "    optimizer = optim.AdamW(list(model.parameters()))\n",
    "    scheduler_global = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, **scheduler_params)  # goal: maximize Dice score\n",
    "    grad_scaler_global = torch.cuda.amp.GradScaler(\n",
    "        enabled=amp)  # Default parameter\n",
    "    \n",
    "    #best_accuracy = 0.0\n",
    "    #interval = []\n",
    "    #interval_count = 0\n",
    "    #validation_accuracy_progression = []\n",
    "    #validation_loss_progression = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        #running_train_loss = 0.0\n",
    "        #running_accuracy = 0.0\n",
    "        #running_vall_loss = 0.0\n",
    "        #total = 0\n",
    "        with tqdm(total=len(train_loader)*train_loader.batch_size, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar_train:\n",
    "            # Training Loop\n",
    "            it = 0\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            for data in train_loader: \n",
    "                model.train()\n",
    "                loss, acc = trainStepFun(model, data, optimizer)\n",
    "                #running_train_loss += loss #  # track the loss value\n",
    "                \n",
    "                it+=1#data[0].shape[0]\n",
    "                epoch_loss += loss\n",
    "                epoch_acc += acc\n",
    "\n",
    "                pbar_train.update(data[0].shape[0])\n",
    "                pbar_train.set_postfix(**{'training loss (batch)': epoch_loss/it, \"training accuracy (batch)\": epoch_acc/it})\n",
    "    \n",
    "            # Calculate training loss value \n",
    "            #train_loss_value = running_train_loss/len(train_loader)\n",
    "\n",
    "        \n",
    "        with tqdm(total=len(validate_loader)*validate_loader.batch_size, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar_validate:\n",
    "            # Validation Loop \n",
    "            it = 0\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            with torch.no_grad(): # Why not ?\n",
    "                for data in validate_loader:\n",
    "                    model.eval()\n",
    "                    ## loss, acc = trainStepFun(model, data)\n",
    "                    loss, acc = testStepFun(model, data)\n",
    "\n",
    "                    # The label with the highest value will be our prediction \n",
    "                    #running_vall_loss += loss\n",
    "                    #total += 1\n",
    "                    #running_accuracy += acc\n",
    "                    it+=1#data[0].shape[0]\n",
    "                    epoch_loss += loss\n",
    "                    epoch_acc += acc\n",
    "\n",
    "                    pbar_validate.update(data[0].shape[0])\n",
    "                    pbar_validate.set_postfix(**{'validation loss (batch)': epoch_loss/it, \"validation accuracy (batch)\": epoch_acc/it})\n",
    "                                                \n",
    "                    #validation_accuracy_progression.append(acc)\n",
    "                    #validation_loss_progression.append(loss)\n",
    "                    #interval_count += 1\n",
    "                    #interval.append(interval_count)\n",
    "    \n",
    "        # Calculate validation loss value \n",
    "        #val_loss_value = running_vall_loss/len(validate_loader) \n",
    "                \n",
    "        # Calculate accuracy as the number of correct predictions in the validation batch divided by the total number of predictions done.  \n",
    "        #accuracy = (100.0 * running_accuracy / total)     \n",
    " \n",
    "        # Save the model if the accuracy is the best \n",
    "        #if accuracy > best_accuracy:\n",
    "        #    torch.save(model.state_dict(), save_folder +\n",
    "        #               \"/newtork_weigths/model_epoch{:}_validation_accuracy{:.3f}_train_loss{:.3f}.pth\".format(epoch, accuracy, train_loss_value))\n",
    "        #    best_accuracy = accuracy\n",
    "         \n",
    "        # Print the statistics of the epoch \n",
    "        #print('Completed training batch', epoch, 'Training Loss is: %.4f' %train_loss_value,\n",
    "        #       'Validation Loss is: %.4f' %val_loss_value, 'Accuracy is %d %%' % (accuracy))\n",
    "        \"\"\"\n",
    "        validation_accuracy_smooth = smooth(validation_accuracy_progression, 0.99)\n",
    "        validation_loss_smooth = smooth(validation_loss_progression, 0.99)\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.clf()\n",
    "        plt.plot(interval, validation_accuracy_smooth,\n",
    "                 'g-', label='Global accuracy')\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Accuracy Value\")\n",
    "        plt.title(\"Accuracy Monitoring among validation\")\n",
    "        plt.legend()\n",
    "        plt.savefig(save_folder+\"/training_monitoring/accuracy_\" +\n",
    "                    str(epoch)+\"_epoch.png\")\n",
    "        \n",
    "        if (epoch == epochs):\n",
    "            plt.show()\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.clf()\n",
    "        plt.plot(interval, validation_loss_smooth,\n",
    "                 'r-', label='Global loss')\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Loss Value\")\n",
    "        plt.title(\"Loss Monitoring among validation\")\n",
    "        plt.legend()\n",
    "        plt.savefig(save_folder+\"/training_monitoring/loss_\" +\n",
    "                    str(epoch)+\"_epoch.png\")\n",
    "        \n",
    "        if (epoch == epochs):\n",
    "            plt.show()\n",
    "        \"\"\"\n",
    "\n",
    "    # Return the fully trained model\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the model\n",
    "def test(model, test_loader, testStepFun):\n",
    "    iter = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    with tqdm(total=len(test_loader)*test_loader.batch_size, desc=f'Testing', unit='img') as pbar_test:\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                loss, acc = testStepFun(model, data)\n",
    "\n",
    "                iter += 1\n",
    "                epoch_loss += loss\n",
    "                epoch_acc += acc\n",
    "                \n",
    "\n",
    "                pbar_test.update(data[0].shape[0])\n",
    "                pbar_test.set_postfix(**{'test loss': epoch_loss/iter, \"test accuracy\": epoch_acc/iter})\n",
    "    return epoch_loss/iter , epoch_acc/iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 42000/42000 [01:14<00:00, 562.58img/s, training accuracy (batch)=0.914, training loss (batch)=tensor(0.3095, device='cuda:0', grad_fn=<DivBackward0>)]\n",
      "Epoch 1/10: 100%|██████████| 9000/9000 [00:09<00:00, 976.77img/s, validation accuracy (batch)=0.947, validation loss (batch)=0.173] \n",
      "Epoch 2/10: 100%|██████████| 42000/42000 [01:11<00:00, 590.57img/s, training accuracy (batch)=0.963, training loss (batch)=tensor(0.1266, device='cuda:0', grad_fn=<DivBackward0>)] \n",
      "Epoch 2/10: 100%|██████████| 9000/9000 [00:04<00:00, 2240.33img/s, validation accuracy (batch)=0.964, validation loss (batch)=0.12] \n",
      "Epoch 3/10: 100%|██████████| 42000/42000 [01:14<00:00, 565.38img/s, training accuracy (batch)=0.976, training loss (batch)=tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)]\n",
      "Epoch 3/10: 100%|██████████| 9000/9000 [00:09<00:00, 961.93img/s, validation accuracy (batch)=0.971, validation loss (batch)=0.0983] \n",
      "Epoch 4/10: 100%|██████████| 42000/42000 [01:13<00:00, 569.02img/s, training accuracy (batch)=0.983, training loss (batch)=tensor(0.0545, device='cuda:0', grad_fn=<DivBackward0>)] \n",
      "Epoch 4/10: 100%|██████████| 9000/9000 [00:08<00:00, 1006.04img/s, validation accuracy (batch)=0.975, validation loss (batch)=0.0858]\n",
      "Epoch 5/10: 100%|██████████| 42000/42000 [01:14<00:00, 566.11img/s, training accuracy (batch)=0.989, training loss (batch)=tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>)]\n",
      "Epoch 5/10: 100%|██████████| 9000/9000 [00:09<00:00, 977.56img/s, validation accuracy (batch)=0.977, validation loss (batch)=0.0881] \n",
      "Epoch 6/10: 100%|██████████| 42000/42000 [01:13<00:00, 568.58img/s, training accuracy (batch)=0.992, training loss (batch)=tensor(0.0261, device='cuda:0', grad_fn=<DivBackward0>)] \n",
      "Epoch 6/10: 100%|██████████| 9000/9000 [00:09<00:00, 993.61img/s, validation accuracy (batch)=0.976, validation loss (batch)=0.0891] \n",
      "Epoch 7/10: 100%|██████████| 42000/42000 [01:14<00:00, 564.67img/s, training accuracy (batch)=0.995, training loss (batch)=tensor(0.0178, device='cuda:0', grad_fn=<DivBackward0>)]\n",
      "Epoch 7/10: 100%|██████████| 9000/9000 [00:09<00:00, 987.76img/s, validation accuracy (batch)=0.977, validation loss (batch)=0.0853] \n",
      "Epoch 8/10: 100%|██████████| 42000/42000 [01:14<00:00, 565.44img/s, training accuracy (batch)=0.996, training loss (batch)=tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)]\n",
      "Epoch 8/10: 100%|██████████| 9000/9000 [00:08<00:00, 1007.23img/s, validation accuracy (batch)=0.974, validation loss (batch)=0.0985]\n",
      "Epoch 9/10:  58%|█████▊    | 24400/42000 [00:44<00:31, 553.57img/s, training accuracy (batch)=0.997, training loss (batch)=tensor(0.0099, device='cuda:0', grad_fn=<DivBackward0>)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-81925eb459f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mteacher_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_teacher_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/newtork_weigths/teacher_model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-29f7d00dc649>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, validate_loader, trainStepFun, testStepFun, epochs)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainStepFun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0;31m#running_train_loss += loss #  # track the loss value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4dcb26e9ea8a>\u001b[0m in \u001b[0;36mtrainStep\u001b[0;34m(model, data, optimizer)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \taccuracy = float(torch.sum(torch.argmax(\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "teacher_model = train(load_teacher_model(), train_dataloader, validation_dataloader, trainStep, testStep, n_epochs)\n",
    "save_model(teacher_model, save_folder+\"/newtork_weigths/teacher_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_1 = []\n",
    "\n",
    "models_2 = []\n",
    "\n",
    "n_models = 40\n",
    "\n",
    "\n",
    "for i in range(30, n_models):\n",
    "      l1_size = int(1+i*1)\n",
    "      # Train models without distillation\n",
    "      model = train(load_model(GenericNetwork(l1_size)), train_dataloader, validation_dataloader, trainStep, testStep, n_epochs)\n",
    "      models_1.append(model)\n",
    "      save_model(model, save_folder+\"/newtork_weigths/no_distillation_first_layer_size_{:}.pth\".format(l1_size))\n",
    "\n",
    "      model = train(load_model(GenericNetwork(l1_size)), train_dataloader, validation_dataloader, studentTrainStepDistillationMNIST, testStep, n_epochs)\n",
    "      models_2.append(model)\n",
    "      save_model(model, save_folder+\"/newtork_weigths/distillation_first_layer_size_{:}.pth\".format(l1_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainable_param(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    return sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_distilled_model_paths = get_path_list(save_folder+\"/newtork_weigths\", \"no_distillation\")\n",
    "not_distilled_size = get_last_number_in_name(not_distilled_model_paths)\n",
    "\n",
    "# Code to order model_paths and param by param in ascending order\n",
    "not_distilled_model_paths = [x for _,x in sorted(zip(not_distilled_size,not_distilled_model_paths))]\n",
    "not_distilled_size = sorted(not_distilled_size)\n",
    "\n",
    "# Load the not distilled models in a list, initiating the GenericNetwork model with the correct size\n",
    "not_distilled_models = []\n",
    "for i in range(len(not_distilled_model_paths)):\n",
    "    not_distilled_models.append(load_model(GenericNetwork(not_distilled_size[i]), not_distilled_model_paths[i]))\n",
    "\n",
    "distilled_model_paths = get_path_list(save_folder+\"/newtork_weigths\", \"distillation\")\n",
    "distilled_size = get_last_number_in_name(distilled_model_paths)\n",
    "\n",
    "# Code to order model_paths and param by param in ascending order\n",
    "distilled_model_paths = [x for _,x in sorted(zip(distilled_size,distilled_model_paths))]\n",
    "distilled_size = sorted(distilled_size)\n",
    "\n",
    "# Load the distilled models in a list, initiating the GenericNetwork model with the correct size\n",
    "distilled_models = []\n",
    "for i in range(len(distilled_model_paths)):\n",
    "    distilled_models.append(load_model(GenericNetwork(distilled_size[i]), distilled_model_paths[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing models without distillation\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2964.82img/s, test accuracy=0.271, test loss=1.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3037.41img/s, test accuracy=0.404, test loss=1.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3035.61img/s, test accuracy=0.666, test loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3066.15img/s, test accuracy=0.658, test loss=0.973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3175.39img/s, test accuracy=0.806, test loss=0.659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2885.67img/s, test accuracy=0.877, test loss=0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2917.27img/s, test accuracy=0.882, test loss=0.399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3002.97img/s, test accuracy=0.902, test loss=0.339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2902.42img/s, test accuracy=0.9, test loss=0.344]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2985.83img/s, test accuracy=0.907, test loss=0.319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3024.83img/s, test accuracy=0.912, test loss=0.306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2855.48img/s, test accuracy=0.913, test loss=0.291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3000.16img/s, test accuracy=0.917, test loss=0.29] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2968.82img/s, test accuracy=0.913, test loss=0.295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2967.29img/s, test accuracy=0.921, test loss=0.269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2979.60img/s, test accuracy=0.923, test loss=0.266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2990.74img/s, test accuracy=0.918, test loss=0.278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3023.14img/s, test accuracy=0.923, test loss=0.258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2947.17img/s, test accuracy=0.926, test loss=0.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3140.82img/s, test accuracy=0.926, test loss=0.255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2972.88img/s, test accuracy=0.925, test loss=0.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2976.25img/s, test accuracy=0.921, test loss=0.261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3001.72img/s, test accuracy=0.927, test loss=0.25] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2936.38img/s, test accuracy=0.927, test loss=0.248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2946.50img/s, test accuracy=0.925, test loss=0.255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2970.54img/s, test accuracy=0.93, test loss=0.243] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3087.58img/s, test accuracy=0.932, test loss=0.234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3171.95img/s, test accuracy=0.929, test loss=0.246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3049.76img/s, test accuracy=0.928, test loss=0.243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3084.53img/s, test accuracy=0.935, test loss=0.225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3134.75img/s, test accuracy=0.934, test loss=0.231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:02<00:00, 3006.71img/s, test accuracy=0.938, test loss=0.221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2976.62img/s, test accuracy=0.939, test loss=0.214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9000/9000 [00:03<00:00, 2990.10img/s, test accuracy=0.93, test loss=0.236] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  89%|████████▉ | 8030/9000 [00:02<00:00, 3897.46img/s, test accuracy=0.936, test loss=0.221]"
     ]
    }
   ],
   "source": [
    "not_distilled_loss = []\n",
    "not_distilled_accuracy = []\n",
    "not_distilled_param = []\n",
    "\n",
    "print(\"Testing models without distillation\")\n",
    "for i in range(0, len(not_distilled_models)):\n",
    "    print(i)\n",
    "    model = not_distilled_models[i]\n",
    "    not_distilled_param.append(get_trainable_param(model))\n",
    "    loss, acc = test(model, test_dataloader, testStep)\n",
    "    not_distilled_loss.append(loss)\n",
    "    not_distilled_accuracy.append(acc)\n",
    "\n",
    "distilled_loss = []\n",
    "distilled_accuracy = []\n",
    "distilled_param = []\n",
    "\n",
    "print(\"Testing models with distillation\")\n",
    "for i in range(0, len(distilled_models)):\n",
    "    print(i)\n",
    "    model = distilled_models[i]\n",
    "    distilled_param.append(get_trainable_param(model))\n",
    "    loss, acc = test(model, test_dataloader, testStep)\n",
    "    distilled_loss.append(loss)\n",
    "    distilled_accuracy.append(acc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT ACCURACY\n",
    "\n",
    "# Plot accuracy in respect to the number of parameters\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.plot(not_distilled_param, not_distilled_accuracy,\n",
    "            'g-', label='No distillation')\n",
    "plt.plot(distilled_param, distilled_accuracy,\n",
    "            'r-', label='Distillation')\n",
    "plt.xlabel(\"Number of parameters\")\n",
    "plt.ylabel(\"Accuracy Value\")\n",
    "plt.title(\"Accuracy Monitoring among models\")\n",
    "plt.legend()\n",
    "plt.savefig(save_folder+\"/training_monitoring/accuracy_param.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plot the gain in accuracy in respect to the number of parameters for the distilled models\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.plot(distilled_param, np.array(distilled_accuracy)-np.array(not_distilled_accuracy),\n",
    "            'r-', label='Gain')\n",
    "plt.xlabel(\"Number of parameters\")\n",
    "plt.ylabel(\"Accuracy Value\")\n",
    "plt.title(\"Accuracy Gain Monitoring among models\")\n",
    "plt.legend()\n",
    "plt.savefig(save_folder+\"/training_monitoring/accuracy_gain_param.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# PLOT LOSS\n",
    "\n",
    "# Plot loss in respect to the number of parameters\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.plot(not_distilled_param, not_distilled_loss,\n",
    "            'g-', label='No distillation')\n",
    "plt.plot(distilled_param, distilled_loss,\n",
    "            'r-', label='Distillation')\n",
    "plt.xlabel(\"Number of parameters\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.title(\"Loss Monitoring among models\")\n",
    "plt.legend()\n",
    "plt.savefig(save_folder+\"/training_monitoring/loss_param.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the gain in loss in respect to the number of parameters for the distilled models\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.plot(distilled_param, np.array(not_distilled_loss)-np.array(distilled_loss),\n",
    "            'r-', label='Gain')\n",
    "plt.xlabel(\"Number of parameters\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.title(\"Loss Gain Monitoring among models\")\n",
    "plt.legend()\n",
    "plt.savefig(save_folder+\"/training_monitoring/loss_gain_param.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3985, 7960, 11935, 15910, 19885, 23860, 27835, 31810, 35785, 39760, 43735, 47710, 51685, 55660, 59635, 63610, 67585, 71560, 75535, 79510]\n",
      "[0.8595555555555504, 0.9107777777777708, 0.9184444444444372, 0.9225555555555486, 0.9225555555555488, 0.9346666666666612, 0.935777777777772, 0.9402222222222156, 0.9403333333333271, 0.9419999999999942, 0.9458888888888832, 0.9454444444444383, 0.9503333333333278, 0.9502222222222173, 0.9505555555555497, 0.951444444444439, 0.9516666666666611, 0.9548888888888838, 0.9542222222222169, 0.9537777777777721]\n",
      "[0.48209938913997674, 0.31040350023864044, 0.2706572735764914, 0.2633619197126892, 0.26183317240017157, 0.22978122368765375, 0.21613859336978444, 0.19500613021767801, 0.2058396381688201, 0.20151937724194594, 0.18795951169656797, 0.18656296602217481, 0.17293473891008437, 0.17506865181080583, 0.17108642537715948, 0.16463028802109572, 0.16246265242704086, 0.15888001071547883, 0.15536700959213906, 0.15288772719873425]\n",
      "[3985, 7960, 11935, 15910, 19885, 23860, 27835, 31810, 35785, 39760, 43735, 47710, 51685, 55660, 59635, 63610, 67585, 71560, 75535, 79510]\n",
      "[0.8429999999999946, 0.9055555555555485, 0.919222222222215, 0.9216666666666601, 0.9297777777777712, 0.9297777777777715, 0.9395555555555496, 0.938444444444438, 0.9415555555555495, 0.9455555555555494, 0.9476666666666611, 0.9508888888888837, 0.9528888888888836, 0.9536666666666619, 0.952444444444439, 0.9555555555555502, 0.9534444444444394, 0.9551111111111052, 0.9552222222222176, 0.9582222222222174]\n",
      "[0.569556293413043, 0.33549268600220483, 0.2931495285510189, 0.275625636426525, 0.24917841363284324, 0.24713333011501365, 0.22464169071987272, 0.22556892309958737, 0.211869160624014, 0.19907051449331145, 0.1904714519644363, 0.18425179282927678, 0.17888420990047355, 0.17736308383548424, 0.17137465596768178, 0.1627530543262967, 0.17159141255439156, 0.1622920365585014, 0.16544419664475654, 0.14933990500349964]\n"
     ]
    }
   ],
   "source": [
    "print(not_distilled_param)\n",
    "print(not_distilled_accuracy)\n",
    "print(not_distilled_loss)\n",
    "\n",
    "print(distilled_param)\n",
    "print(distilled_accuracy)\n",
    "print(distilled_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'global_step =  0\\nn_train = len(filtered_train_data)\\nprint(n_train)\\n\\nT = 1.0 # temperature for distillation loss\\n# Using a higher value for T produces a softer probability distribution over classes\\nalpha = 1.0\\n# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\\n# loss = alpha * st + (1 - alpha) * tt\\n\\nprint(\"Starting Training Loop...\")\\n\\n\\nsource_dice = []\\nintervalle = []\\n\\nL_seg_list = []\\n\\nloss_list = []\\nacc_list = []\\n\\nL_s_list = []\\n\\ncompteur_plot = 0\\n\\nfor epoch in range(num_epochs):\\n    epoch_loss = 0\\n    epoch_acc = 0\\n    cpt_it = 0\\n    with tqdm(total=n_train, desc=f\\'Epoch {epoch + 1}/{num_epochs}\\', unit=\\'img\\') as pbar:\\n\\n        for i, data in enumerate(filtered_train_dataloader, 0):\\n            student_model.train()\\n            teacher_model.eval()\\n\\n            cpt_it += 1\\n\\n            X, y = data\\n\\n            X = X.to(\\n                device=device, dtype=torch.float32)\\n            y = y.to(\\n                device=device, dtype=torch.long)\\n\\n            # Pass Data Trought net before optimizing everything\\n\\n            loss, acc = studentTrainStep(teacher_model, student_model, studentLoss, optimizer_global, X, y, T, alpha)\\n            \\n\\n            L_global = loss\\n\\n            ###########################################################\\n            # Evaluation on the Training Set\\n            ###########################################################\\n\\n            student_model.eval()\\n\\n            intervalle.append(compteur_plot)\\n            compteur_plot += 1\\n\\n            global_step += 1\\n            epoch_loss += loss.item()\\n            epoch_acc += acc\\n\\n            pbar.update(X.shape[0])\\n            pbar.set_postfix(\\n                **{\\'loss (batch)\\': epoch_loss/cpt_it, \"accuracy (batch)\": epoch_acc/cpt_it})\\n            # pbar.set_postfix(**{\\'dice target\\': dice_target})\\n\\n            loss_list.append(loss.item())\\n            acc_list.append(acc)\\n# print(\"whole epoch target dice mean :\", sum(dice_score_target)/cpt_it)\\n        if (epoch % batch_save_interval == 0):  # and epoch != 0 :\\n\\n            loss_smooth = smooth(loss_list, 0.99)\\n            acc_smooth = smooth(acc_list, 0.99)\\n\\n            torch.save(student_model.state_dict(), saving_folder +\\n                       \"/newtork_weigths/net_epoch{:}_acc{:.3f}_loss{:.3f}.pth\".format(epoch, epoch_acc/cpt_it, epoch_loss/cpt_it))\\n\\n            plt.figure(1)\\n            plt.clf()\\n            plt.plot(intervalle, acc_smooth, \\'r-\\', label=\\'Global accuracy\\')\\n            plt.xlabel(\"iterations\")\\n            plt.ylabel(\"Accuracy Value\")\\n            plt.title(\"Accuracy Monitoring among training\")\\n            plt.legend()\\n            plt.savefig(saving_folder+\"/training_monitoring/acc_\" +\\n                        str(epoch)+\"_epoch.png\")\\n            plt.show()\\n\\n            plt.figure(1)\\n            plt.clf()\\n            plt.plot(intervalle, loss_smooth, \\'r-\\', label=\\'Global loss\\')\\n            plt.xlabel(\"iterations\")\\n            plt.ylabel(\"Loss Value\")\\n            plt.title(\"Loss Monitoring among training\")\\n            plt.legend()\\n            plt.savefig(saving_folder+\"/training_monitoring/loss_\" +\\n                        str(epoch)+\"_epoch.png\")\\n            plt.show()'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"global_step =  0\n",
    "n_train = len(filtered_train_data)\n",
    "print(n_train)\n",
    "\n",
    "T = 1.0 # temperature for distillation loss\n",
    "# Using a higher value for T produces a softer probability distribution over classes\n",
    "alpha = 1.0\n",
    "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
    "# loss = alpha * st + (1 - alpha) * tt\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "\n",
    "source_dice = []\n",
    "intervalle = []\n",
    "\n",
    "L_seg_list = []\n",
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "L_s_list = []\n",
    "\n",
    "compteur_plot = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    cpt_it = 0\n",
    "    with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='img') as pbar:\n",
    "\n",
    "        for i, data in enumerate(filtered_train_dataloader, 0):\n",
    "            student_model.train()\n",
    "            teacher_model.eval()\n",
    "\n",
    "            cpt_it += 1\n",
    "\n",
    "            X, y = data\n",
    "\n",
    "            X = X.to(\n",
    "                device=device, dtype=torch.float32)\n",
    "            y = y.to(\n",
    "                device=device, dtype=torch.long)\n",
    "\n",
    "            # Pass Data Trought net before optimizing everything\n",
    "\n",
    "            loss, acc = studentTrainStep(teacher_model, student_model, studentLoss, optimizer_global, X, y, T, alpha)\n",
    "            \n",
    "\n",
    "            L_global = loss\n",
    "\n",
    "            ###########################################################\n",
    "            # Evaluation on the Training Set\n",
    "            ###########################################################\n",
    "\n",
    "            student_model.eval()\n",
    "\n",
    "            intervalle.append(compteur_plot)\n",
    "            compteur_plot += 1\n",
    "\n",
    "            global_step += 1\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "\n",
    "            pbar.update(X.shape[0])\n",
    "            pbar.set_postfix(\n",
    "                **{'loss (batch)': epoch_loss/cpt_it, \"accuracy (batch)\": epoch_acc/cpt_it})\n",
    "            # pbar.set_postfix(**{'dice target': dice_target})\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "            acc_list.append(acc)\n",
    "# print(\"whole epoch target dice mean :\", sum(dice_score_target)/cpt_it)\n",
    "        if (epoch % batch_save_interval == 0):  # and epoch != 0 :\n",
    "\n",
    "            loss_smooth = smooth(loss_list, 0.99)\n",
    "            acc_smooth = smooth(acc_list, 0.99)\n",
    "\n",
    "            torch.save(student_model.state_dict(), saving_folder +\n",
    "                       \"/newtork_weigths/net_epoch{:}_acc{:.3f}_loss{:.3f}.pth\".format(epoch, epoch_acc/cpt_it, epoch_loss/cpt_it))\n",
    "\n",
    "            plt.figure(1)\n",
    "            plt.clf()\n",
    "            plt.plot(intervalle, acc_smooth, 'r-', label='Global accuracy')\n",
    "            plt.xlabel(\"iterations\")\n",
    "            plt.ylabel(\"Accuracy Value\")\n",
    "            plt.title(\"Accuracy Monitoring among training\")\n",
    "            plt.legend()\n",
    "            plt.savefig(saving_folder+\"/training_monitoring/acc_\" +\n",
    "                        str(epoch)+\"_epoch.png\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(1)\n",
    "            plt.clf()\n",
    "            plt.plot(intervalle, loss_smooth, 'r-', label='Global loss')\n",
    "            plt.xlabel(\"iterations\")\n",
    "            plt.ylabel(\"Loss Value\")\n",
    "            plt.title(\"Loss Monitoring among training\")\n",
    "            plt.legend()\n",
    "            plt.savefig(saving_folder+\"/training_monitoring/loss_\" +\n",
    "                        str(epoch)+\"_epoch.png\")\n",
    "            plt.show()\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb5e5b18ee203a6716e147d61d87e90492f0bff6defd22583400cdaccb6acdb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
